{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl (173kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 11.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement not upgraded as not directly required: numpy>=1.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.16.4)\n",
      "Requirement not upgraded as not directly required: scipy>=0.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement not upgraded as not directly required: scikit-learn>=0.21 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (0.21.2)\n",
      "Requirement not upgraded as not directly required: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (0.13.2)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.5.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 314 #used to help randomly select the data points\n",
    "TEST_PCT = 0.3 # 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('creditcard2.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Time','Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 80% for the training set and 20% for the testing set\n",
    "train, test = train_test_split(dataset, test_size=TEST_PCT,random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 0:28]\n",
    "y = train.iloc[:,28:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 199036), (1, 199036)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 199036), (1, 199036)]\n"
     ]
    }
   ],
   "source": [
    "X = X_resampled\n",
    "y = y_resampled\n",
    "print(sorted(Counter(y).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1108 19:40:35.174302 140413557581632 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1108 19:40:35.189141 140413557581632 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1108 19:40:35.191180 140413557581632 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1108 19:40:35.219061 140413557581632 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1108 19:40:35.233352 140413557581632 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1108 19:40:35.236747 140413557581632 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(28, input_dim=28, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.9827e-05 - acc: 1.0000\n",
      "Epoch 2/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.5616e-05 - acc: 1.0000\n",
      "Epoch 3/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.1521e-05 - acc: 1.0000\n",
      "Epoch 4/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2626e-05 - acc: 1.0000\n",
      "Epoch 5/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7697e-05 - acc: 1.0000\n",
      "Epoch 6/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.8348e-05 - acc: 1.0000\n",
      "Epoch 7/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.6517e-05 - acc: 1.0000\n",
      "Epoch 8/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7302e-05 - acc: 1.0000\n",
      "Epoch 9/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.0442e-05 - acc: 1.0000\n",
      "Epoch 10/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.3704e-05 - acc: 1.0000\n",
      "Epoch 11/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7315e-05 - acc: 1.0000\n",
      "Epoch 12/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.8125e-05 - acc: 1.0000\n",
      "Epoch 13/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.5363e-05 - acc: 1.0000\n",
      "Epoch 14/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.0002e-05 - acc: 1.0000\n",
      "Epoch 15/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.1004e-05 - acc: 1.0000\n",
      "Epoch 16/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0413e-04 - acc: 1.0000\n",
      "Epoch 17/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.5598e-05 - acc: 1.0000\n",
      "Epoch 18/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7696e-05 - acc: 1.0000\n",
      "Epoch 19/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.5769e-05 - acc: 1.0000\n",
      "Epoch 20/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.9068e-05 - acc: 1.0000\n",
      "Epoch 21/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.3031e-05 - acc: 1.0000\n",
      "Epoch 22/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9431e-05 - acc: 1.0000\n",
      "Epoch 23/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.5352e-05 - acc: 1.0000\n",
      "Epoch 24/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.4147e-05 - acc: 1.0000\n",
      "Epoch 25/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.5920e-05 - acc: 1.0000\n",
      "Epoch 26/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.4605e-05 - acc: 1.0000\n",
      "Epoch 27/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.5080e-05 - acc: 1.0000\n",
      "Epoch 28/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.3119e-04 - acc: 1.0000\n",
      "Epoch 29/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2284e-05 - acc: 1.0000\n",
      "Epoch 30/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2784e-05 - acc: 1.0000\n",
      "Epoch 31/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.8738e-05 - acc: 1.0000\n",
      "Epoch 32/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0828e-05 - acc: 1.0000\n",
      "Epoch 33/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.0887e-05 - acc: 1.0000\n",
      "Epoch 34/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.2558e-04 - acc: 1.0000\n",
      "Epoch 35/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2462e-05 - acc: 1.0000\n",
      "Epoch 36/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.5800e-05 - acc: 1.0000\n",
      "Epoch 37/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9544e-05 - acc: 1.0000\n",
      "Epoch 38/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.8459e-05 - acc: 1.0000\n",
      "Epoch 39/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2301e-05 - acc: 1.0000\n",
      "Epoch 40/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2319e-05 - acc: 1.0000\n",
      "Epoch 41/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.0782e-05 - acc: 1.0000\n",
      "Epoch 42/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0246e-04 - acc: 1.0000\n",
      "Epoch 43/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.1808e-05 - acc: 1.0000\n",
      "Epoch 44/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0362e-04 - acc: 1.0000\n",
      "Epoch 45/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.1108e-05 - acc: 1.0000\n",
      "Epoch 46/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0264e-05 - acc: 1.0000\n",
      "Epoch 47/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.7099e-05 - acc: 1.0000\n",
      "Epoch 48/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.3728e-04 - acc: 1.0000\n",
      "Epoch 49/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.3188e-05 - acc: 1.0000\n",
      "Epoch 50/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0964e-04 - acc: 1.0000\n",
      "Epoch 51/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.8431e-05 - acc: 1.0000\n",
      "Epoch 52/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7525e-05 - acc: 1.0000\n",
      "Epoch 53/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2532e-05 - acc: 1.0000\n",
      "Epoch 54/200\n",
      "398072/398072 [==============================] - 2s 5us/step - loss: 6.2508e-05 - acc: 1.0000\n",
      "Epoch 55/200\n",
      "398072/398072 [==============================] - 3s 7us/step - loss: 8.1487e-05 - acc: 1.0000\n",
      "Epoch 56/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.4833e-05 - acc: 1.0000\n",
      "Epoch 57/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.5813e-05 - acc: 1.0000\n",
      "Epoch 58/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4217e-05 - acc: 1.0000\n",
      "Epoch 59/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.8856e-05 - acc: 1.0000\n",
      "Epoch 60/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.4042e-05 - acc: 1.0000\n",
      "Epoch 61/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.9250e-05 - acc: 1.0000\n",
      "Epoch 62/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3251e-05 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.6235e-05 - acc: 1.0000\n",
      "Epoch 64/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2856e-05 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.3262e-05 - acc: 1.0000\n",
      "Epoch 66/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.8160e-05 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4878e-05 - acc: 1.0000\n",
      "Epoch 68/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4251e-05 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9781e-05 - acc: 1.0000\n",
      "Epoch 70/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9722e-05 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6200e-05 - acc: 1.0000\n",
      "Epoch 72/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.4391e-04 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.2678e-04 - acc: 1.0000\n",
      "Epoch 74/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.7003e-05 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3481e-05 - acc: 1.0000\n",
      "Epoch 76/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.2915e-05 - acc: 1.0000\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.3551e-05 - acc: 1.0000\n",
      "Epoch 78/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6648e-05 - acc: 1.0000\n",
      "Epoch 79/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0294e-05 - acc: 1.0000\n",
      "Epoch 80/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4170e-05 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.1278e-05 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.1422e-05 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.4768e-05 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6507e-05 - acc: 1.0000\n",
      "Epoch 85/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.9416e-05 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.1245e-05 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.0041e-05 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.8330e-05 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.8179e-05 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.5984e-05 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.8003e-05 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.1038e-05 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.8924e-05 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.6600e-05 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0416e-04 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.8777e-05 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.1846e-05 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3889e-05 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7255e-05 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.3067e-05 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7249e-05 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0282e-05 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2684e-05 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.4157e-05 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7807e-05 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.7205e-05 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0111e-04 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2911e-05 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0533e-05 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.1446e-04 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 2.1203e-04 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.0174e-04 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.1442e-04 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6683e-05 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4505e-05 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9052e-05 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.5350e-05 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.5255e-05 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.2551e-05 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.9938e-05 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.7551e-05 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2295e-05 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6898e-05 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.5068e-05 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.5268e-04 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.4040e-04 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0546e-05 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.3001e-05 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9320e-05 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7037e-05 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.5125e-05 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.5840e-05 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.4753e-05 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.6204e-05 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.9525e-05 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.4308e-04 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.2076e-04 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.6096e-05 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2333e-05 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.1014e-05 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.3051e-05 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.8857e-05 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.2419e-05 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3421e-05 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.0819e-05 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.2615e-05 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7422e-05 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6515e-05 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.3637e-05 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7922e-05 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.0411e-05 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.5829e-05 - acc: 1.0000\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.0835e-05 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.3223e-05 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0328e-05 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.1340e-05 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.0485e-05 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.6938e-05 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.7497e-05 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4152e-05 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.9308e-05 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.6314e-05 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.7020e-05 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.9620e-05 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.6042e-05 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4482e-05 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "398072/398072 [==============================] - 3s 8us/step - loss: 9.2206e-05 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 1.2320e-04 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.8690e-05 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.3442e-05 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.1082e-05 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.9259e-05 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4642e-05 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.3809e-05 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.3578e-05 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.7211e-05 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3175e-05 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.5440e-05 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.9142e-05 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4718e-05 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.1695e-05 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.1758e-05 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 9.0909e-05 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.6845e-05 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.9758e-05 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.3838e-05 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.9365e-05 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.0189e-05 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 4.6408e-05 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.5190e-05 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 8.2952e-05 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.0284e-05 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.3363e-05 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 4.9924e-05 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.1315e-05 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 6.4107e-05 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.7957e-05 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 7.4078e-05 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 5.9127e-05 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "398072/398072 [==============================] - 2s 4us/step - loss: 4.8231e-05 - acc: 1.0000\n",
      "398072/398072 [==============================] - 10s 24us/step\n",
      "Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, batch_size=1000)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.iloc[:, 0:28]\n",
    "y_true = test.iloc[:,28:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "LABELS = [\"Normal\",\"Fraud\"]\n",
    "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel() \n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85279\n",
      "           1       0.78      0.82      0.80       164\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.89      0.91      0.90     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9992158515033414\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy Score: \", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.783625730994152\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision Score: \", precision_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
