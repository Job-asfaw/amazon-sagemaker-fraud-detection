{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook\n",
    "\n",
    "This notebook was automatically generated by the AutoML job **xgb-c1-2020-04-11-22-09-21-981**.\n",
    "This notebook allows you to customize the candidate definitions and execute the SageMaker Autopilot workflow.\n",
    "\n",
    "The dataset has **21** columns and the column named **y** is used as\n",
    "the target column. This is being treated as a **BinaryClassification** problem. The dataset also has **2** classes.\n",
    "This notebook will build a **[BinaryClassification](https://en.wikipedia.org/wiki/Binary_classification)** model that\n",
    "**maximizes** the \"**ACCURACY**\" quality metric of the trained models.\n",
    "The \"**ACCURACY**\" metric provides the percentage of times the model predicted the correct class.\n",
    "\n",
    "As part of the AutoML job, the input dataset has been randomly split into two pieces, one for **training** and one for\n",
    "**validation**. This notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively\n",
    "train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO)\n",
    "job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "Look for sections like this for recommended settings that you can change.\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Sagemaker Setup](#Sagemaker-Setup)\n",
    "    1. [Downloading Generated Candidates](#Downloading-Generated-Modules)\n",
    "    1. [SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration](#SageMaker-Autopilot-Job-and-Amazon-Simple-Storage-Service-(Amazon-S3)-Configuration)\n",
    "1. [Candidate Pipelines](#Candidate-Pipelines)\n",
    "    1. [Generated Candidates](#Generated-Candidates)\n",
    "    1. [Selected Candidates](#Selected-Candidates)\n",
    "1. [Executing the Candidate Pipelines](#Executing-the-Candidate-Pipelines)\n",
    "    1. [Run Data Transformation Steps](#Run-Data-Transformation-Steps)\n",
    "    1. [Multi Algorithm Hyperparameter Tuning](#Multi-Algorithm-Hyperparameter-Tuning)\n",
    "1. [Model Selection and Deployment](#Model-Selection-and-Deployment)\n",
    "    1. [Tuning Job Result Overview](#Tuning-Job-Result-Overview)\n",
    "    1. [Model Deployment](#Model-Deployment)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Setup\n",
    "\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "- Check environment & dependencies.\n",
    "- Create a few helper objects/function to organize input/output data and SageMaker sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimal Environment Requirements**\n",
    "\n",
    "- Jupyter: Tested on `JupyterLab 1.0.6`, `jupyter_core 4.5.0` and `IPython 6.4.0`\n",
    "- Kernel: `conda_python3`\n",
    "- Dependencies required\n",
    "  - `sagemaker-python-sdk>=v1.43.4`\n",
    "- Expected Execution Role/permission\n",
    "  - S3 access to the bucket that stores the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Generated Modules\n",
    "Download the generated data transformation modules and an SageMaker Autopilot helper module used by this notebook.\n",
    "Those artifacts will be downloaded to **xgb-c1-2020-04-11-22-09-21-981-artifacts** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p xgb-c1-2020-04-11-22-09-21-981-artifacts\n",
    "!aws s3 sync s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/sagemaker-automl-candidates/pr-1-4b34747772154bc0b1d5924ce17aa391a9917a53f2084af6b9542512b9/generated_module xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module --only-show-errors\n",
    "!aws s3 sync s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/sagemaker-automl-candidates/pr-1-4b34747772154bc0b1d5924ce17aa391a9917a53f2084af6b9542512b9/notebooks/sagemaker_automl xgb-c1-2020-04-11-22-09-21-981-artifacts/sagemaker_automl --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"xgb-c1-2020-04-11-22-09-21-981-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will\n",
    "look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This notebook is initialized to use the following configuration: \n",
       "        <table>\n",
       "        <tr><th colspan=2>Name</th><th>Value</th></tr>\n",
       "        <tr><th>General</th><th>Role</th><td>arn:aws:iam::262002448484:role/service-role/AmazonSageMaker-ExecutionRole-20190606T095855</td></tr>\n",
       "        <tr><th rowspan=2>Base AutoML Job</th><th>Job Name</th><td>xgb-c1-2020-04-11-22-09-21-981</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981</td></tr>\n",
       "        <tr><th rowspan=5>Interactive Job</th><th>Job Name</th><td>xgb-c1-202-notebook-run-11-22-41-31</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/xgb-c1-202-notebook-run-11-22-41-31</td></tr>\n",
       "        <tr><th>Data Processing Trained Model Directory</th><td>s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/xgb-c1-202-notebook-run-11-22-41-31/data-processor-models</td></tr>\n",
       "        <tr><th>Data Processing Transformed Output</th><td>s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/xgb-c1-202-notebook-run-11-22-41-31/transformed-data</td></tr>\n",
       "        <tr><th>Algo Tuning Model Output Directory</th><td>s3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/xgb-c1-202-notebook-run-11-22-41-31/multi-algo-tuning</td></tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_automl import uid, AutoMLLocalRunConfig\n",
    "\n",
    "# Where the preprocessed data from the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'xgb-c1-2020-04-11-22-09-21-981'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981',\n",
    "    'data_transformer_image_repo_version': '0.1.0-cpu-py3',\n",
    "    'algo_image_repo_versions': {'xgboost': '0.90-1-cpu-py3', 'linear-learner': 'latest'}\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'xgb-c1-202-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://sagemaker-us-west-1-262002448484/sagemaker/DEMO-automl-dm/output/xgb-c1-2020-04-11-22-09-21-981/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "    'data_processing_model_dir': 'data-processor-models',\n",
    "    'data_processing_transformed_output_dir': 'transformed-data',\n",
    "    'multi_algo_tuning_output_dir': 'multi-algo-tuning'\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG = AutoMLLocalRunConfig(\n",
    "    role='arn:aws:iam::262002448484:role/service-role/AmazonSageMaker-ExecutionRole-20190606T095855',\n",
    "    base_automl_job_config=BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config=LOCAL_AUTOML_JOB_CONFIG,\n",
    "    security_config={'EnableInterContainerTrafficEncryption': False, 'VpcConfig': {}})\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Pipelines\n",
    "\n",
    "The `AutoMLLocalRunner` keeps track of selected candidates and automates many of the steps needed to execute feature engineering and tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl import AutoMLInteractiveRunner, AutoMLLocalCandidate\n",
    "\n",
    "automl_interactive_runner = AutoMLInteractiveRunner(AUTOML_LOCAL_RUN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Candidates\n",
    "\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated **10** machine learning\n",
    "pipeline(s) that use **2** algorithm(s). Each pipeline contains a set of feature transformers and an\n",
    "algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. The resource configuration: instance type & count\n",
    "1. Select candidate pipeline definitions by cells\n",
    "1. The linked data transformation script can be reviewed and updated. Please refer to the [README.md](./xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/README.md) for detailed customization instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp0-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp0.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp0\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp1-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp1.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp1\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp2-linear-learner](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp2.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp2\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp3-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp3.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp3\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp4-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp4.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp4\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp5-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp5.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp5\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp6-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp6.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp6\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp7-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp7.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp7\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp8-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp8.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp8\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp9-xgboost](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp9.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp9\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Candidates\n",
    "\n",
    "You have selected the following candidates (please run the cell below and click on the feature transformer links for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <table>\n",
       "            <tr><th>Candidate Name</th><th>Algorithm</th><th>Feature Transformer</th></tr>\n",
       "            <tr><th>dpp0-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp0.py'>dpp0.py</a></td></tr>\n",
       "<tr><th>dpp1-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp1.py'>dpp1.py</a></td></tr>\n",
       "<tr><th>dpp2-linear-learner</th><td>linear-learner</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp2.py'>dpp2.py</a></td></tr>\n",
       "<tr><th>dpp3-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp3.py'>dpp3.py</a></td></tr>\n",
       "<tr><th>dpp4-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp4.py'>dpp4.py</a></td></tr>\n",
       "<tr><th>dpp5-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp5.py'>dpp5.py</a></td></tr>\n",
       "<tr><th>dpp6-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp6.py'>dpp6.py</a></td></tr>\n",
       "<tr><th>dpp7-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp7.py'>dpp7.py</a></td></tr>\n",
       "<tr><th>dpp8-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp8.py'>dpp8.py</a></td></tr>\n",
       "<tr><th>dpp9-xgboost</th><td>xgboost</td><td><a href='xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp9.py'>dpp9.py</a></td></tr>\n",
       "            </table>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_interactive_runner.display_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering pipeline consists of two SageMaker jobs:\n",
    "\n",
    "1. Generated trainable data transformer Python modules like [dpp0.py](xgb-c1-2020-04-11-22-09-21-981-artifacts/generated_module/candidate_data_processors/dpp0.py), which has been downloaded to local file system\n",
    "2. A **training** job to train the data transformers\n",
    "3. A **batch transform** job to apply the trained transformation to the dataset to generate the algorithm compatible data\n",
    "\n",
    "The transformers and its training pipeline are built using open sourced **[sagemaker-scikit-learn-container][]** and **[sagemaker-scikit-learn-extension][]**.\n",
    "\n",
    "[sagemaker-scikit-learn-container]: https://github.com/aws/sagemaker-scikit-learn-container\n",
    "[sagemaker-scikit-learn-extension]: https://github.com/aws/sagemaker-scikit-learn-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Candidate Pipelines\n",
    "\n",
    "Each candidate pipeline consists of two steps, feature transformation and algorithm training.\n",
    "For efficiency first execute the feature transformation step which will generate a featurized dataset on S3\n",
    "for each pipeline.\n",
    "\n",
    "After each featurized dataset is prepared, execute a multi-algorithm tuning job that will run tuning jobs\n",
    "in parallel for each pipeline. This tuning job will execute training jobs to find the best set of\n",
    "hyper-parameters for each pipeline, as well as finding the overall best performing pipeline.\n",
    "\n",
    "### Run Data Transformation Steps\n",
    "\n",
    "Now you are ready to start execution all data transformation steps.  The cell below may take some time to finish,\n",
    "feel free to go grab a cup of coffee. To expedite the process you can set the number of `parallel_jobs` to be up to 10.\n",
    "Please check the account limits to increase the limits before increasing the number of jobs to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 23:27:23,537 INFO root: [Worker_0:dpp0-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:23,541 INFO root: [Worker_5:dpp5-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:23,770 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp5-train-11-23-27-22\n",
      "2020-04-11 23:27:23,783 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp0-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:27:23 Starting - Starting the training job\n",
      "2020-04-11 23:27:24 Starting - Starting the training job2020-04-11 23:27:24,542 INFO root: [Worker_3:dpp3-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:24,543 INFO root: [Worker_6:dpp6-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:24,618 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\n",
      "2020-04-11 23:27:24,644 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp3-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:27:27 Starting - Starting the training job\n",
      "2020-04-11 23:27:26 Starting - Launching requested ML instances\n",
      "2020-04-11 23:27:25 Starting - Launching requested ML instances2020-04-11 23:27:29,544 INFO root: [Worker_4:dpp4-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:29,633 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp4-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:27:29 Starting - Starting the training job2020-04-11 23:27:30,545 INFO root: [Worker_1:dpp1-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:30,623 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp1-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:27:31 Starting - Starting the training job2020-04-11 23:27:31,548 INFO root: [Worker_2:dpp2-linear-learner]Executing step: train_data_transformer\n",
      "2020-04-11 23:27:31,635 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp2-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:27:31 Starting - Starting the training job\n",
      "2020-04-11 23:27:30 Starting - Launching requested ML instances\n",
      "2020-04-11 23:27:33 Starting - Starting the training job..\n",
      "2020-04-11 23:27:32 Starting - Launching requested ML instances\n",
      "2020-04-11 23:27:32 Starting - Launching requested ML instances\n",
      "2020-04-11 23:27:33 Starting - Launching requested ML instances.\n",
      "2020-04-11 23:27:34 Starting - Launching requested ML instances....................................................................\n",
      "2020-04-11 23:28:27 Starting - Preparing the instances for training.\n",
      "2020-04-11 23:28:26 Starting - Preparing the instances for training...\n",
      "2020-04-11 23:28:31 Starting - Preparing the instances for training.\n",
      "2020-04-11 23:28:33 Starting - Preparing the instances for training..\n",
      "2020-04-11 23:28:30 Starting - Preparing the instances for training\n",
      "2020-04-11 23:28:33 Starting - Preparing the instances for training.........................\n",
      "2020-04-11 23:28:52 Starting - Preparing the instances for training...\n",
      "2020-04-11 23:28:57 Downloading - Downloading input data......................\n",
      "2020-04-11 23:29:09 Downloading - Downloading input data.\n",
      "2020-04-11 23:29:12 Downloading - Downloading input data.\n",
      "2020-04-11 23:29:14 Downloading - Downloading input data\n",
      "2020-04-11 23:29:15 Training - Downloading the training image........\n",
      "2020-04-11 23:29:22 Training - Downloading the training image........\n",
      "2020-04-11 23:29:28 Training - Downloading the training image..\n",
      "2020-04-11 23:29:28 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:29:33 Downloading - Downloading input data....\n",
      "2020-04-11 23:29:32 Training - Downloading the training image..\n",
      "2020-04-11 23:29:36 Training - Training image download completed. Training in progress.....\n",
      "2020-04-11 23:29:39 Uploading - Uploading generated training model...\n",
      "2020-04-11 23:29:42 Training - Training image download completed. Training in progress..\n",
      "2020-04-11 23:29:46 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:29:46 Completed - Training job completed\n",
      ".\n",
      "2020-04-11 23:29:47 Uploading - Uploading generated training model.2020-04-11 23:29:50,417 INFO root: [Worker_6:dpp6-xgboost]Executing step: create_transformer_model\n",
      "\n",
      "2020-04-11 23:29:47 Uploading - Uploading generated training model2020-04-11 23:29:50,715 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\n",
      "..2020-04-11 23:29:53,065 INFO root: [Worker_6:dpp6-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:29:53,066 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp6-transform-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:29:48 Training - Downloading the training image\n",
      "2020-04-11 23:29:53 Completed - Training job completed\n",
      "\n",
      "2020-04-11 23:29:53 Downloading - Downloading input data\n",
      "2020-04-11 23:29:54 Completed - Training job completed\n",
      "2020-04-11 23:29:55,876 INFO root: [Worker_0:dpp0-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:29:55,900 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp0-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:29:52 Downloading - Downloading input data2020-04-11 23:29:57,222 INFO root: [Worker_0:dpp0-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:29:57,223 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp0-transform-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:29:57 Uploading - Uploading generated training model......2020-04-11 23:30:02,678 INFO root: [Worker_4:dpp4-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:30:02,747 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp4-train-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:30:02 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:30:00 Training - Downloading the training image..\n",
      "2020-04-11 23:30:04 Completed - Training job completed\n",
      ".\n",
      "2020-04-11 23:30:08 Uploading - Uploading generated training model.2020-04-11 23:30:10,114 INFO root: [Worker_4:dpp4-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:30:10,115 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp4-transform-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:30:07 Training - Downloading the training image...\n",
      "2020-04-11 23:30:14 Training - Training image download completed. Training in progress..2020-04-11 23:30:16,701 INFO root: [Worker_2:dpp2-linear-learner]Executing step: create_transformer_model\n",
      "2020-04-11 23:30:16,723 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp2-train-11-23-27-22\n",
      "...\n",
      "2020-04-11 23:30:15 Completed - Training job completed\n",
      "\n",
      "2020-04-11 23:30:19 Uploading - Uploading generated training model.\n",
      "2020-04-11 23:30:21 Training - Training image download completed. Training in progress.....2020-04-11 23:30:26,044 INFO root: [Worker_2:dpp2-linear-learner]Executing step: perform_data_transform\n",
      "2020-04-11 23:30:26,047 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp2-transform-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:30:26 Uploading - Uploading generated training model2020-04-11 23:30:27,029 INFO root: [Worker_1:dpp1-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:30:27,052 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp1-train-11-23-27-22\n",
      "..\n",
      "2020-04-11 23:30:26 Completed - Training job completed\n",
      ".2020-04-11 23:30:31,138 INFO root: [Worker_5:dpp5-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:30:31,161 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp5-train-11-23-27-22\n",
      "..2020-04-11 23:30:32,485 INFO root: [Worker_5:dpp5-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:30:32,486 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp5-transform-11-23-27-22\n",
      "...2020-04-11 23:30:35,428 INFO root: [Worker_1:dpp1-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:30:35,429 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp1-transform-11-23-27-22\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 23:30:33 Completed - Training job completed\n",
      "...2020-04-11 23:30:39,085 INFO root: [Worker_3:dpp3-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:30:39,110 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp3-train-11-23-27-22\n",
      "...2020-04-11 23:30:41,433 INFO root: [Worker_3:dpp3-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:30:41,434 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp3-transform-11-23-27-22\n",
      ".....................................................................................................................................................................................................................!\n",
      "2020-04-11 23:33:14,177 INFO root: Successfully fit data transformer for dpp6-xgboost\n",
      "...2020-04-11 23:33:17,180 INFO root: [Worker_6:dpp7-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:33:17,251 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp7-train-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:33:17 Starting - Starting the training job!\n",
      "2020-04-11 23:33:18,402 INFO root: Successfully fit data transformer for dpp0-xgboost\n",
      ".....\n",
      "2020-04-11 23:33:20 Starting - Launching requested ML instances.....2020-04-11 23:33:27,403 INFO root: [Worker_0:dpp8-xgboost]Executing step: train_data_transformer\n",
      ".2020-04-11 23:33:27,472 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp8-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:33:27 Starting - Starting the training job......\n",
      "2020-04-11 23:33:30 Starting - Launching requested ML instances................!\n",
      "2020-04-11 23:33:46,471 INFO root: Successfully fit data transformer for dpp1-xgboost\n",
      "!\n",
      "2020-04-11 23:33:47,224 INFO root: Successfully fit data transformer for dpp2-linear-learner\n",
      "....!\n",
      "2020-04-11 23:33:51,337 INFO root: Successfully fit data transformer for dpp4-xgboost\n",
      "!\n",
      "2020-04-11 23:33:52,506 INFO root: Successfully fit data transformer for dpp3-xgboost\n",
      "...2020-04-11 23:33:54,479 INFO root: [Worker_1:dpp9-xgboost]Executing step: train_data_transformer\n",
      "2020-04-11 23:33:54,553 INFO sagemaker: Creating training-job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp9-train-11-23-27-22\n",
      "\n",
      "2020-04-11 23:33:54 Starting - Starting the training job...\n",
      "2020-04-11 23:33:56 Starting - Launching requested ML instances..!\n",
      "2020-04-11 23:34:03,663 INFO root: Successfully fit data transformer for dpp5-xgboost\n",
      "..........\n",
      "2020-04-11 23:34:22 Starting - Preparing the instances for training......\n",
      "2020-04-11 23:34:31 Starting - Preparing the instances for training...............\n",
      "2020-04-11 23:34:57 Starting - Preparing the instances for training...\n",
      "2020-04-11 23:35:05 Downloading - Downloading input data...\n",
      "2020-04-11 23:35:08 Downloading - Downloading input data.....\n",
      "2020-04-11 23:35:21 Training - Downloading the training image.\n",
      "2020-04-11 23:35:23 Training - Downloading the training image......\n",
      "2020-04-11 23:35:34 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:35:36 Downloading - Downloading input data\n",
      "2020-04-11 23:35:39 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:35:40 Uploading - Uploading generated training model.\n",
      "2020-04-11 23:35:45 Uploading - Uploading generated training model\n",
      "2020-04-11 23:35:47 Completed - Training job completed\n",
      ".\n",
      "2020-04-11 23:35:51 Completed - Training job completed\n",
      ".2020-04-11 23:35:56,312 INFO root: [Worker_6:dpp7-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:35:56,336 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp7-train-11-23-27-22\n",
      "2020-04-11 23:35:57,416 INFO root: [Worker_0:dpp8-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:35:57,439 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp8-train-11-23-27-22\n",
      "2020-04-11 23:35:59,727 INFO root: [Worker_6:dpp7-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:35:59,728 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp7-transform-11-23-27-22\n",
      ".\n",
      "2020-04-11 23:35:56 Training - Downloading the training image..2020-04-11 23:36:06,766 INFO root: [Worker_0:dpp8-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:36:06,767 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp8-transform-11-23-27-22\n",
      "..\n",
      "2020-04-11 23:36:09 Training - Training image download completed. Training in progress......\n",
      "2020-04-11 23:36:19 Uploading - Uploading generated training model.....\n",
      "2020-04-11 23:36:26 Completed - Training job completed\n",
      "...2020-04-11 23:36:38,626 INFO root: [Worker_1:dpp9-xgboost]Executing step: create_transformer_model\n",
      "2020-04-11 23:36:38,649 INFO sagemaker: Creating model with name: xgb-c1-202-notebook-run-11-22-41-31-dpp9-train-11-23-27-22\n",
      "...2020-04-11 23:36:46,988 INFO root: [Worker_1:dpp9-xgboost]Executing step: perform_data_transform\n",
      "2020-04-11 23:36:46,989 INFO sagemaker: Creating transform job with name: xgb-c1-202-notebook-run-11-22-41-31-dpp9-transform-11-23-27-22\n",
      "......................................................................................!\n",
      "2020-04-11 23:39:10,817 INFO root: Successfully fit data transformer for dpp7-xgboost\n",
      "..!\n",
      "2020-04-11 23:39:17,918 INFO root: Successfully fit data transformer for dpp8-xgboost\n",
      "................!\n",
      "2020-04-11 23:40:38,299 INFO root: Successfully fit data transformer for dpp9-xgboost\n",
      "2020-04-11 23:40:38,299 INFO root: Successfully fit 10 data transformers\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.fit_data_transformers(parallel_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Algorithm Hyperparameter Tuning\n",
    "\n",
    "Now that the algorithm compatible trasformed datasets are ready, you can start the multi-algorithm model tuning job\n",
    "to find the best predictive model. The following algorithm training job configuration for each\n",
    "algorithm is auto-generated by the AutoML Job as part of the recommendation.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Hyperparameter ranges\n",
    "2. Objective metrics\n",
    "3. Recommended static algorithm hyperparameters.\n",
    "\n",
    "Please refers to [Xgboost tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) and [Linear learner tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) for detailed explanations of the parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML recommendation job has recommended the following hyperparameters, objectives and accuracy metrics for\n",
    "the algorithm and problem type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_OBJECTIVE_METRICS = {\n",
    "    'xgboost': 'validation:accuracy',\n",
    "    'linear-learner': 'validation:binary_classification_accuracy',\n",
    "}\n",
    "\n",
    "STATIC_HYPERPARAMETERS = {\n",
    "    'xgboost': {\n",
    "        'objective': 'binary:hinge',\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'loss': 'logistic',\n",
    "        'mini_batch_size': 800,\n",
    "        'binary_classifier_model_selection_criteria': 'loss_function',\n",
    "        'num_models': 1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tunable hyperparameters search ranges are recommended for the Multi-Algo tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "    'xgboost': {\n",
    "        'num_round': IntegerParameter(2, 512, scaling_type='Logarithmic'),\n",
    "        'max_depth': IntegerParameter(2, 32, scaling_type='Logarithmic'),\n",
    "        'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "        'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "        'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "        'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "        'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "        'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "        'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'wd': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'l1': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'learning_rate': ContinuousParameter(1e-5, 1.0, scaling_type='Logarithmic'),\n",
    "        'positive_example_weight_mult': CategoricalParameter(['balanced', '0.01', '1', '100']),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi-Algorithm Tuner Input\n",
    "\n",
    "To use the multi-algorithm HPO tuner, prepare some inputs and parameters. Prepare a dictionary whose key is the name of the trained pipeline candidates and the values are respectively:\n",
    "\n",
    "1. Estimators for the recommended algorithm\n",
    "2. Hyperparameters search ranges\n",
    "3. Objective metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_parameters = automl_interactive_runner.prepare_multi_algo_parameters(\n",
    "    objective_metrics=ALGORITHM_OBJECTIVE_METRICS,\n",
    "    static_hyperparameters=STATIC_HYPERPARAMETERS,\n",
    "    hyperparameters_search_ranges=ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you prepare the inputs data to the multi-algo tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_inputs = automl_interactive_runner.prepare_multi_algo_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Multi-Algorithm Tuner\n",
    "\n",
    "With the recommended Hyperparameter ranges and the transformed dataset, create a multi-algorithm model tuning job\n",
    "that coordinates hyper parameter optimizations across the different possible algorithms and feature processing strategies.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Tuner strategy: [Bayesian](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization), [Random Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)\n",
    "2. Objective type: `Minimize`, `Maximize`, see [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "3. Max Job size: the max number of training jobs HPO would be launching to run experiments. Note the default value is **250**\n",
    "    which is the default of the managed flow.\n",
    "4. Parallelism. Number of jobs that will be executed in parallel. Higher value will expedite the tuning process.\n",
    "    Please check the account limits to increase the limits before increasing the number of jobs to run in parallel\n",
    "5. Please use a different tuning job name if you re-run this cell after applied customizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "base_tuning_job_name = \"{}-tuning\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name)\n",
    "\n",
    "tuner = HyperparameterTuner.create(\n",
    "    base_tuning_job_name=base_tuning_job_name,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize',\n",
    "    max_parallel_jobs=7,\n",
    "    max_jobs=250,\n",
    "    **multi_algo_tuning_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Multi-Algorithm Tuning\n",
    "\n",
    "Now you are ready to start running the **Multi-Algo Tuning** job. After the job is finished, store the tuning job name which you use to select models in the next section.\n",
    "The tuning process will take some time, please track the progress in the Amazon SageMaker Hyperparameter tuning jobs console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 23:41:56,740 INFO root: _TuningJob.start_new!!!\n",
      "2020-04-11 23:41:56,745 INFO sagemaker: Creating hyperparameter tuning job with name: xgb-c1-202-notebook--200411-2341\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tuning Job xgb-c1-202-notebook--200411-2341 started, please track the progress from [here](https://us-west-1.console.aws.amazon.com/sagemaker/home?region=us-west-1#/hyper-tuning-jobs/xgb-c1-202-notebook--200411-2341)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Run tuning\n",
    "tuner.fit(inputs=multi_algo_tuning_inputs, include_cls_metadata=None)\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "display(\n",
    "    Markdown(f\"Tuning Job {tuning_job_name} started, please track the progress from [here](https://{AUTOML_LOCAL_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_RUN_CONFIG.region}#/hyper-tuning-jobs/{tuning_job_name})\"))\n",
    "\n",
    "# Wait for tuning job to finish\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Deployment\n",
    "\n",
    "This section guides you through the model selection process. Afterward, you construct an inference pipeline\n",
    "on Amazon SageMaker to host the best candidate.\n",
    "\n",
    "Because you executed the feature transformation and algorithm training in two separate steps, you now need to manually\n",
    "link each trained model with the feature transformer that it is associated with. When running a regular Amazon\n",
    "SageMaker Autopilot job, this will automatically be done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Job Result Overview\n",
    "\n",
    "The performance of each candidate pipeline can be viewed as a Pandas dataframe. For more interactive usage please\n",
    "refers to [model tuning monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingJobDefinitionName</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>alpha</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>l1</th>\n",
       "      <th>lambda</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>num_round</th>\n",
       "      <th>positive_example_weight_mult</th>\n",
       "      <th>subsample</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.918978</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-04-12 00:42:46+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-127-733d3050</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:41:41+00:00</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.873918</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>6.118777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.849376</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.918722</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2020-04-12 00:27:13+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-095-57108b48</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:26:03+00:00</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.884270</td>\n",
       "      <td>0.216711</td>\n",
       "      <td>21.586894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.577044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.847793</td>\n",
       "      <td>204.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.917827</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2020-04-12 01:28:06+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-218-7b5ee65d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:26:37+00:00</td>\n",
       "      <td>0.259029</td>\n",
       "      <td>0.979356</td>\n",
       "      <td>0.108421</td>\n",
       "      <td>15.715688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>378.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.917827</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2020-04-12 00:18:15+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-077-afcfcd58</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:16:36+00:00</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.628456</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>23.284713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>441.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.917572</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2020-04-12 00:44:17+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-130-00168bce</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:42:58+00:00</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.898442</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>15.217189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.240728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.917316</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2020-04-12 01:37:54+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-237-91f92591</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:36:54+00:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.948516</td>\n",
       "      <td>0.568853</td>\n",
       "      <td>24.269321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917316</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2020-04-12 01:39:28+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-241-6925ce3a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:38:09+00:00</td>\n",
       "      <td>0.113147</td>\n",
       "      <td>0.703614</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.063952</td>\n",
       "      <td>481.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899242</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.917188</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2020-04-12 00:02:38+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-046-2dd0cff3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:01:47+00:00</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.835274</td>\n",
       "      <td>0.315955</td>\n",
       "      <td>31.027451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.917188</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2020-04-12 01:16:04+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-195-26f03e7b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:14:50+00:00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.767375</td>\n",
       "      <td>0.194379</td>\n",
       "      <td>38.928994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>253.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.917061</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2020-04-12 00:02:56+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-048-28dbcf51</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:02:07+00:00</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.348582</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.917061</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2020-04-12 00:42:59+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-128-0df8ac56</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:41:44+00:00</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.346528</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>11.552716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.916933</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2020-04-12 01:17:32+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-197-8db50b1d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:15:54+00:00</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.767321</td>\n",
       "      <td>0.207305</td>\n",
       "      <td>19.884455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>425.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.916805</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2020-04-12 00:22:51+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-086-25ceea5b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:21:27+00:00</td>\n",
       "      <td>1.123676</td>\n",
       "      <td>0.643149</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.916805</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2020-04-12 00:55:43+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-153-d0aebac1</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:54:28+00:00</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.812152</td>\n",
       "      <td>0.451911</td>\n",
       "      <td>0.131833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.548179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.916550</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2020-04-12 00:55:21+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-154-8dd2096a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:54:23+00:00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.656297</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.635820</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.916550</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2020-04-12 00:41:27+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-125-032b9abd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:40:28+00:00</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.303779</td>\n",
       "      <td>0.137879</td>\n",
       "      <td>1.046619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.158950</td>\n",
       "      <td>159.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.916550</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2020-04-12 01:15:53+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-194-91fc3614</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:14:29+00:00</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.960108</td>\n",
       "      <td>0.040811</td>\n",
       "      <td>27.648042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.567995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.916166</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2020-04-12 00:40:15+00:00</td>\n",
       "      <td>dpp8-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-123-d7092117</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:39:13+00:00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.637936</td>\n",
       "      <td>0.071767</td>\n",
       "      <td>27.282520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951534</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.916038</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2020-04-12 01:33:19+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-229-503068ae</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 01:32:00+00:00</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.665708</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.172477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.044974</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.915911</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2020-04-12 00:27:32+00:00</td>\n",
       "      <td>dpp6-xgboost</td>\n",
       "      <td>xgb-c1-202-notebook--200411-2341-096-d8988b77</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020-04-12 00:26:28+00:00</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.322317</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.699609</td>\n",
       "      <td>297.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FinalObjectiveValue  TrainingElapsedTimeSeconds  \\\n",
       "123             0.918978                        65.0   \n",
       "155             0.918722                        70.0   \n",
       "32              0.917827                        89.0   \n",
       "173             0.917827                        99.0   \n",
       "120             0.917572                        79.0   \n",
       "13              0.917316                        60.0   \n",
       "9               0.917316                        79.0   \n",
       "204             0.917188                        51.0   \n",
       "55              0.917188                        74.0   \n",
       "202             0.917061                        49.0   \n",
       "122             0.917061                        75.0   \n",
       "53              0.916933                        98.0   \n",
       "164             0.916805                        84.0   \n",
       "97              0.916805                        75.0   \n",
       "96              0.916550                        58.0   \n",
       "125             0.916550                        59.0   \n",
       "56              0.916550                        84.0   \n",
       "127             0.916166                        62.0   \n",
       "21              0.916038                        79.0   \n",
       "154             0.915911                        64.0   \n",
       "\n",
       "              TrainingEndTime TrainingJobDefinitionName  \\\n",
       "123 2020-04-12 00:42:46+00:00              dpp6-xgboost   \n",
       "155 2020-04-12 00:27:13+00:00              dpp8-xgboost   \n",
       "32  2020-04-12 01:28:06+00:00              dpp6-xgboost   \n",
       "173 2020-04-12 00:18:15+00:00              dpp8-xgboost   \n",
       "120 2020-04-12 00:44:17+00:00              dpp8-xgboost   \n",
       "13  2020-04-12 01:37:54+00:00              dpp6-xgboost   \n",
       "9   2020-04-12 01:39:28+00:00              dpp6-xgboost   \n",
       "204 2020-04-12 00:02:38+00:00              dpp8-xgboost   \n",
       "55  2020-04-12 01:16:04+00:00              dpp6-xgboost   \n",
       "202 2020-04-12 00:02:56+00:00              dpp8-xgboost   \n",
       "122 2020-04-12 00:42:59+00:00              dpp8-xgboost   \n",
       "53  2020-04-12 01:17:32+00:00              dpp6-xgboost   \n",
       "164 2020-04-12 00:22:51+00:00              dpp8-xgboost   \n",
       "97  2020-04-12 00:55:43+00:00              dpp6-xgboost   \n",
       "96  2020-04-12 00:55:21+00:00              dpp6-xgboost   \n",
       "125 2020-04-12 00:41:27+00:00              dpp8-xgboost   \n",
       "56  2020-04-12 01:15:53+00:00              dpp6-xgboost   \n",
       "127 2020-04-12 00:40:15+00:00              dpp8-xgboost   \n",
       "21  2020-04-12 01:33:19+00:00              dpp6-xgboost   \n",
       "154 2020-04-12 00:27:32+00:00              dpp6-xgboost   \n",
       "\n",
       "                                   TrainingJobName TrainingJobStatus  \\\n",
       "123  xgb-c1-202-notebook--200411-2341-127-733d3050         Completed   \n",
       "155  xgb-c1-202-notebook--200411-2341-095-57108b48         Completed   \n",
       "32   xgb-c1-202-notebook--200411-2341-218-7b5ee65d         Completed   \n",
       "173  xgb-c1-202-notebook--200411-2341-077-afcfcd58         Completed   \n",
       "120  xgb-c1-202-notebook--200411-2341-130-00168bce         Completed   \n",
       "13   xgb-c1-202-notebook--200411-2341-237-91f92591         Completed   \n",
       "9    xgb-c1-202-notebook--200411-2341-241-6925ce3a         Completed   \n",
       "204  xgb-c1-202-notebook--200411-2341-046-2dd0cff3         Completed   \n",
       "55   xgb-c1-202-notebook--200411-2341-195-26f03e7b         Completed   \n",
       "202  xgb-c1-202-notebook--200411-2341-048-28dbcf51         Completed   \n",
       "122  xgb-c1-202-notebook--200411-2341-128-0df8ac56         Completed   \n",
       "53   xgb-c1-202-notebook--200411-2341-197-8db50b1d         Completed   \n",
       "164  xgb-c1-202-notebook--200411-2341-086-25ceea5b         Completed   \n",
       "97   xgb-c1-202-notebook--200411-2341-153-d0aebac1         Completed   \n",
       "96   xgb-c1-202-notebook--200411-2341-154-8dd2096a         Completed   \n",
       "125  xgb-c1-202-notebook--200411-2341-125-032b9abd         Completed   \n",
       "56   xgb-c1-202-notebook--200411-2341-194-91fc3614         Completed   \n",
       "127  xgb-c1-202-notebook--200411-2341-123-d7092117         Completed   \n",
       "21   xgb-c1-202-notebook--200411-2341-229-503068ae         Completed   \n",
       "154  xgb-c1-202-notebook--200411-2341-096-d8988b77         Completed   \n",
       "\n",
       "            TrainingStartTime     alpha  colsample_bytree       eta  \\\n",
       "123 2020-04-12 00:41:41+00:00  0.009812          0.873918  0.028251   \n",
       "155 2020-04-12 00:26:03+00:00  0.000005          0.884270  0.216711   \n",
       "32  2020-04-12 01:26:37+00:00  0.259029          0.979356  0.108421   \n",
       "173 2020-04-12 00:16:36+00:00  0.017566          0.628456  0.008520   \n",
       "120 2020-04-12 00:42:58+00:00  0.000003          0.898442  0.080735   \n",
       "13  2020-04-12 01:36:54+00:00  0.000011          0.948516  0.568853   \n",
       "9   2020-04-12 01:38:09+00:00  0.113147          0.703614  0.021005   \n",
       "204 2020-04-12 00:01:47+00:00  0.000217          0.835274  0.315955   \n",
       "55  2020-04-12 01:14:50+00:00  0.000002          0.767375  0.194379   \n",
       "202 2020-04-12 00:02:07+00:00  0.016889          0.987124  0.348582   \n",
       "122 2020-04-12 00:41:44+00:00  0.000050          0.346528  0.558394   \n",
       "53  2020-04-12 01:15:54+00:00  0.000007          0.767321  0.207305   \n",
       "164 2020-04-12 00:21:27+00:00  1.123676          0.643149  0.014390   \n",
       "97  2020-04-12 00:54:28+00:00  0.000555          0.812152  0.451911   \n",
       "96  2020-04-12 00:54:23+00:00  0.000002          0.300000  0.656297   \n",
       "125 2020-04-12 00:40:28+00:00  0.000012          0.303779  0.137879   \n",
       "56  2020-04-12 01:14:29+00:00  0.000858          0.960108  0.040811   \n",
       "127 2020-04-12 00:39:13+00:00  0.000018          0.637936  0.071767   \n",
       "21  2020-04-12 01:32:00+00:00  0.004566          0.665708  0.005756   \n",
       "154 2020-04-12 00:26:28+00:00  0.005358          0.482569  0.322317   \n",
       "\n",
       "         gamma  l1    lambda  learning_rate  max_depth  min_child_weight  \\\n",
       "123   6.118777 NaN  0.024372            NaN       28.0          0.849376   \n",
       "155  21.586894 NaN  1.577044            NaN       21.0          0.847793   \n",
       "32   15.715688 NaN  0.000039            NaN       29.0          0.015192   \n",
       "173  23.284713 NaN  0.000011            NaN       28.0          0.000002   \n",
       "120  15.217189 NaN  0.240728            NaN       32.0          0.000068   \n",
       "13   24.269321 NaN  0.001695            NaN        3.0          0.000002   \n",
       "9     0.000102 NaN  0.008775            NaN        9.0          0.063952   \n",
       "204  31.027451 NaN  0.000002            NaN        7.0          0.000001   \n",
       "55   38.928994 NaN  0.003743            NaN       31.0          0.000001   \n",
       "202   0.000011 NaN  0.664581            NaN        3.0          0.001480   \n",
       "122  11.552716 NaN  0.010930            NaN       19.0         32.000000   \n",
       "53   19.884455 NaN  0.091966            NaN       18.0          0.000039   \n",
       "164   0.000713 NaN  0.000245            NaN        9.0          0.037422   \n",
       "97    0.131833 NaN  0.734874            NaN        2.0          0.010674   \n",
       "96    0.000013 NaN  0.032993            NaN        2.0          0.635820   \n",
       "125   1.046619 NaN  0.000021            NaN       16.0         31.158950   \n",
       "56   27.648042 NaN  1.567995            NaN       32.0          0.012442   \n",
       "127  27.282520 NaN  0.015524            NaN       15.0         32.000000   \n",
       "21    0.172477 NaN  0.043569            NaN       26.0         11.044974   \n",
       "154   0.006389 NaN  0.000002            NaN        2.0          6.699609   \n",
       "\n",
       "     num_round positive_example_weight_mult  subsample  wd  \n",
       "123      147.0                          NaN   0.530783 NaN  \n",
       "155      204.0                          NaN   0.693158 NaN  \n",
       "32       378.0                          NaN   0.553868 NaN  \n",
       "173      441.0                          NaN   0.799170 NaN  \n",
       "120      262.0                          NaN   0.668071 NaN  \n",
       "13        69.0                          NaN   0.755431 NaN  \n",
       "9        481.0                          NaN   0.899242 NaN  \n",
       "204       17.0                          NaN   0.840808 NaN  \n",
       "55       253.0                          NaN   0.772319 NaN  \n",
       "202      104.0                          NaN   0.769192 NaN  \n",
       "122      281.0                          NaN   0.981384 NaN  \n",
       "53       425.0                          NaN   0.725690 NaN  \n",
       "164      486.0                          NaN   0.775553 NaN  \n",
       "97       343.0                          NaN   0.548179 NaN  \n",
       "96       207.0                          NaN   0.893430 NaN  \n",
       "125      159.0                          NaN   0.642919 NaN  \n",
       "56       308.0                          NaN   0.578461 NaN  \n",
       "127      239.0                          NaN   0.951534 NaN  \n",
       "21       331.0                          NaN   0.885976 NaN  \n",
       "154      297.0                          NaN   0.643910 NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "SAGEMAKER_SESSION = AUTOML_LOCAL_RUN_CONFIG.sagemaker_session\n",
    "SAGEMAKER_ROLE = AUTOML_LOCAL_RUN_CONFIG.role\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best training job can be selected as below:\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Tips: </strong>\n",
    "You could select alternative job by using the value from `TrainingJobName` column above and assign to `best_training_job` below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Multi Algorithm HPO training job name is xgb-c1-202-notebook--200411-2341-127-733d3050\n"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "best_training_job = attached_tuner.best_training_job()\n",
    "\n",
    "print(\"Best Multi Algorithm HPO training job name is {}\".format(best_training_job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Best Training Job with Feature Pipelines\n",
    "\n",
    "Finally, deploy the best training job to Amazon SageMaker along with its companion feature engineering models.\n",
    "At the end of the section, you get an endpoint that's ready to serve online inference or start batch transform jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/pipeline.html) that has multiple containers of the following:\n",
    "\n",
    "1. Data Transformation Container: a container built from the model we selected and trained during the data transformer sections\n",
    "2. Algorithm Container: a container built from the trained model we selected above from the best HPO training job.\n",
    "3. Inverse Label Transformer Container: a container that converts numerical intermediate prediction value back to non-numerical label value.\n",
    "\n",
    "Get both best data transformation model and algorithm model from best training job and create an pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 03:43:31,467 INFO root: Chosen Data Processing pipeline candidate name is dpp6-xgboost\n",
      "2020-04-11 23:29:46 Starting - Preparing the instances for training\n",
      "2020-04-11 23:29:46 Downloading - Downloading input data\n",
      "2020-04-11 23:29:46 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:29:46 Uploading - Uploading generated training model\n",
      "2020-04-11 23:29:46 Completed - Training job completed\u001b[34m2020-04-11 23:29:29,161 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,163 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,173 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpqa3w7xe9/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=4364 sha256=6d248af31d0c5877c0d4fddf02a50a6571124fea80647151bdb4a382e97a8989\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iwgj36tr/wheels/f0/1b/99/1cde50cce24fa5090ec713f15b2e80ca3ee04ef587c45ff9c9\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:30,671 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,690 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,703 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,713 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"processor_module\": \"dpp6\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"processor_module\":\"dpp6\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"processor_module\":\"dpp6\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\",\"module_name\":\"trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--processor_module\",\"dpp6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSOR_MODULE=dpp6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python trainer.py --processor_module dpp6\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:35,672 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n",
      "2020-04-12 00:42:46 Starting - Preparing the instances for training\n",
      "2020-04-12 00:42:46 Downloading - Downloading input data\n",
      "2020-04-12 00:42:46 Training - Training image download completed. Training in progress.\n",
      "2020-04-12 00:42:46 Uploading - Uploading generated training model\n",
      "2020-04-12 00:42:46 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:accuracy to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:hinge to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[00:42:14] 31303x60 matrix with 1878180 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[00:42:14] 7825x60 matrix with 469500 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : accuracy\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 31303 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 7825 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.887519#011validation-error:0.887412#011train-accuracy:0.112481#011validation-accuracy:0.112588\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.69217#011validation-error:0.69508#011train-accuracy:0.30783#011validation-accuracy:0.30492\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.233268#011validation-error:0.239489#011train-accuracy:0.766732#011validation-accuracy:0.760511\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.198959#011validation-error:0.203834#011train-accuracy:0.801041#011validation-accuracy:0.796166\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.170495#011validation-error:0.177891#011train-accuracy:0.829505#011validation-accuracy:0.822109\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.153596#011validation-error:0.162939#011train-accuracy:0.846404#011validation-accuracy:0.837061\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.140753#011validation-error:0.148371#011train-accuracy:0.859247#011validation-accuracy:0.851629\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.130595#011validation-error:0.138403#011train-accuracy:0.869405#011validation-accuracy:0.861597\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.120116#011validation-error:0.129457#011train-accuracy:0.879884#011validation-accuracy:0.870543\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.113152#011validation-error:0.1223#011train-accuracy:0.886848#011validation-accuracy:0.8777\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.106539#011validation-error:0.1177#011train-accuracy:0.893461#011validation-accuracy:0.8823\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.101779#011validation-error:0.112971#011train-accuracy:0.898221#011validation-accuracy:0.887029\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.098265#011validation-error:0.109265#011train-accuracy:0.901735#011validation-accuracy:0.890735\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.094943#011validation-error:0.105176#011train-accuracy:0.905057#011validation-accuracy:0.894824\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.092483#011validation-error:0.103514#011train-accuracy:0.907517#011validation-accuracy:0.896486\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.090694#011validation-error:0.101086#011train-accuracy:0.909306#011validation-accuracy:0.898914\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.088809#011validation-error:0.099808#011train-accuracy:0.911191#011validation-accuracy:0.900192\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.087659#011validation-error:0.097636#011train-accuracy:0.912341#011validation-accuracy:0.902364\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.086286#011validation-error:0.097125#011train-accuracy:0.913714#011validation-accuracy:0.902875\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.084209#011validation-error:0.096102#011train-accuracy:0.915791#011validation-accuracy:0.903898\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.082292#011validation-error:0.095208#011train-accuracy:0.917708#011validation-accuracy:0.904792\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.081494#011validation-error:0.094313#011train-accuracy:0.918506#011validation-accuracy:0.905687\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.080344#011validation-error:0.094058#011train-accuracy:0.919656#011validation-accuracy:0.905942\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.079577#011validation-error:0.092013#011train-accuracy:0.920423#011validation-accuracy:0.907987\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.078778#011validation-error:0.091885#011train-accuracy:0.921222#011validation-accuracy:0.908115\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.077628#011validation-error:0.091374#011train-accuracy:0.922372#011validation-accuracy:0.908626\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.076478#011validation-error:0.090863#011train-accuracy:0.923522#011validation-accuracy:0.909137\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.074945#011validation-error:0.089585#011train-accuracy:0.925055#011validation-accuracy:0.910415\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.073891#011validation-error:0.088946#011train-accuracy:0.926109#011validation-accuracy:0.911054\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.072549#011validation-error:0.087796#011train-accuracy:0.927451#011validation-accuracy:0.912204\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.072038#011validation-error:0.087284#011train-accuracy:0.927962#011validation-accuracy:0.912716\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.071399#011validation-error:0.08754#011train-accuracy:0.928601#011validation-accuracy:0.91246\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.070696#011validation-error:0.087157#011train-accuracy:0.929304#011validation-accuracy:0.912843\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.070089#011validation-error:0.086006#011train-accuracy:0.929911#011validation-accuracy:0.913994\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.06945#011validation-error:0.085495#011train-accuracy:0.93055#011validation-accuracy:0.914505\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.068332#011validation-error:0.08524#011train-accuracy:0.931668#011validation-accuracy:0.91476\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.067821#011validation-error:0.084728#011train-accuracy:0.932179#011validation-accuracy:0.915272\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.067853#011validation-error:0.083962#011train-accuracy:0.932147#011validation-accuracy:0.916038\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.066703#011validation-error:0.084601#011train-accuracy:0.933297#011validation-accuracy:0.915399\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.066415#011validation-error:0.084984#011train-accuracy:0.933585#011validation-accuracy:0.915016\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.066351#011validation-error:0.084345#011train-accuracy:0.933649#011validation-accuracy:0.915655\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.066128#011validation-error:0.084856#011train-accuracy:0.933872#011validation-accuracy:0.915144\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.065904#011validation-error:0.084728#011train-accuracy:0.934096#011validation-accuracy:0.915272\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.065649#011validation-error:0.084856#011train-accuracy:0.934351#011validation-accuracy:0.915144\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.065169#011validation-error:0.084217#011train-accuracy:0.934831#011validation-accuracy:0.915783\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.065169#011validation-error:0.084345#011train-accuracy:0.934831#011validation-accuracy:0.915655\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.06485#011validation-error:0.084217#011train-accuracy:0.93515#011validation-accuracy:0.915783\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.064722#011validation-error:0.084345#011train-accuracy:0.935278#011validation-accuracy:0.915655\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.064594#011validation-error:0.084473#011train-accuracy:0.935406#011validation-accuracy:0.915527\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.064307#011validation-error:0.084217#011train-accuracy:0.935693#011validation-accuracy:0.915783\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.063604#011validation-error:0.084089#011train-accuracy:0.936396#011validation-accuracy:0.915911\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.063317#011validation-error:0.084345#011train-accuracy:0.936683#011validation-accuracy:0.915655\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.062678#011validation-error:0.084089#011train-accuracy:0.937322#011validation-accuracy:0.915911\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.062869#011validation-error:0.083578#011train-accuracy:0.937131#011validation-accuracy:0.916422\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.062965#011validation-error:0.083706#011train-accuracy:0.937035#011validation-accuracy:0.916294\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.062901#011validation-error:0.084089#011train-accuracy:0.937099#011validation-accuracy:0.915911\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.062965#011validation-error:0.083706#011train-accuracy:0.937035#011validation-accuracy:0.916294\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.062774#011validation-error:0.084089#011train-accuracy:0.937226#011validation-accuracy:0.915911\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.062582#011validation-error:0.084089#011train-accuracy:0.937418#011validation-accuracy:0.915911\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.062486#011validation-error:0.083706#011train-accuracy:0.937514#011validation-accuracy:0.916294\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.062294#011validation-error:0.083834#011train-accuracy:0.937706#011validation-accuracy:0.916166\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.061943#011validation-error:0.083578#011train-accuracy:0.938057#011validation-accuracy:0.916422\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.061655#011validation-error:0.083195#011train-accuracy:0.938345#011validation-accuracy:0.916805\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.061719#011validation-error:0.083067#011train-accuracy:0.938281#011validation-accuracy:0.916933\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.061432#011validation-error:0.082812#011train-accuracy:0.938568#011validation-accuracy:0.917188\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.061592#011validation-error:0.082684#011train-accuracy:0.938408#011validation-accuracy:0.917316\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.061208#011validation-error:0.082812#011train-accuracy:0.938792#011validation-accuracy:0.917188\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.060825#011validation-error:0.0823#011train-accuracy:0.939175#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.060569#011validation-error:0.0823#011train-accuracy:0.939431#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.060346#011validation-error:0.081917#011train-accuracy:0.939654#011validation-accuracy:0.918083\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.06009#011validation-error:0.082428#011train-accuracy:0.93991#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.059643#011validation-error:0.082173#011train-accuracy:0.940357#011validation-accuracy:0.917827\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.059771#011validation-error:0.082556#011train-accuracy:0.940229#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.059291#011validation-error:0.082812#011train-accuracy:0.940709#011validation-accuracy:0.917188\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.058844#011validation-error:0.082556#011train-accuracy:0.941156#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.058812#011validation-error:0.082428#011train-accuracy:0.941188#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.058301#011validation-error:0.082684#011train-accuracy:0.941699#011validation-accuracy:0.917316\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.058365#011validation-error:0.082556#011train-accuracy:0.941635#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.058269#011validation-error:0.082556#011train-accuracy:0.941731#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.058077#011validation-error:0.082428#011train-accuracy:0.941922#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.057854#011validation-error:0.082428#011train-accuracy:0.942146#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.057758#011validation-error:0.0823#011train-accuracy:0.942242#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.057566#011validation-error:0.082428#011train-accuracy:0.942434#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.057598#011validation-error:0.082428#011train-accuracy:0.942402#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[100]#011train-error:0.057439#011validation-error:0.082428#011train-accuracy:0.942561#011validation-accuracy:0.917572\u001b[0m\n",
      "\u001b[34m[101]#011train-error:0.057247#011validation-error:0.082812#011train-accuracy:0.942753#011validation-accuracy:0.917188\u001b[0m\n",
      "\u001b[34m[102]#011train-error:0.056896#011validation-error:0.082684#011train-accuracy:0.943104#011validation-accuracy:0.917316\u001b[0m\n",
      "\u001b[34m[103]#011train-error:0.056832#011validation-error:0.082173#011train-accuracy:0.943168#011validation-accuracy:0.917827\u001b[0m\n",
      "\u001b[34m[104]#011train-error:0.056704#011validation-error:0.0823#011train-accuracy:0.943296#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[105]#011train-error:0.056448#011validation-error:0.082045#011train-accuracy:0.943552#011validation-accuracy:0.917955\u001b[0m\n",
      "\u001b[34m[106]#011train-error:0.056512#011validation-error:0.082556#011train-accuracy:0.943488#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[107]#011train-error:0.056289#011validation-error:0.082556#011train-accuracy:0.943711#011validation-accuracy:0.917444\u001b[0m\n",
      "\u001b[34m[108]#011train-error:0.056225#011validation-error:0.0823#011train-accuracy:0.943775#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[109]#011train-error:0.055745#011validation-error:0.081789#011train-accuracy:0.944255#011validation-accuracy:0.918211\u001b[0m\n",
      "\u001b[34m[110]#011train-error:0.055682#011validation-error:0.081661#011train-accuracy:0.944318#011validation-accuracy:0.918339\u001b[0m\n",
      "\u001b[34m[111]#011train-error:0.055266#011validation-error:0.0823#011train-accuracy:0.944734#011validation-accuracy:0.9177\u001b[0m\n",
      "\u001b[34m[112]#011train-error:0.055458#011validation-error:0.081789#011train-accuracy:0.944542#011validation-accuracy:0.918211\u001b[0m\n",
      "\u001b[34m[113]#011train-error:0.05517#011validation-error:0.081917#011train-accuracy:0.94483#011validation-accuracy:0.918083\u001b[0m\n",
      "\u001b[34m[114]#011train-error:0.054915#011validation-error:0.081917#011train-accuracy:0.945085#011validation-accuracy:0.918083\u001b[0m\n",
      "\u001b[34m[115]#011train-error:0.054947#011validation-error:0.082173#011train-accuracy:0.945053#011validation-accuracy:0.917827\u001b[0m\n",
      "\u001b[34m[116]#011train-error:0.054883#011validation-error:0.082045#011train-accuracy:0.945117#011validation-accuracy:0.917955\u001b[0m\n",
      "\u001b[34m[117]#011train-error:0.054691#011validation-error:0.081917#011train-accuracy:0.945309#011validation-accuracy:0.918083\u001b[0m\n",
      "\u001b[34m[118]#011train-error:0.054436#011validation-error:0.081661#011train-accuracy:0.945564#011validation-accuracy:0.918339\u001b[0m\n",
      "\u001b[34m[119]#011train-error:0.054276#011validation-error:0.081534#011train-accuracy:0.945724#011validation-accuracy:0.918466\u001b[0m\n",
      "\u001b[34m[120]#011train-error:0.053829#011validation-error:0.081406#011train-accuracy:0.946171#011validation-accuracy:0.918594\u001b[0m\n",
      "\u001b[34m[121]#011train-error:0.053765#011validation-error:0.080767#011train-accuracy:0.946235#011validation-accuracy:0.919233\u001b[0m\n",
      "\u001b[34m[122]#011train-error:0.053573#011validation-error:0.081022#011train-accuracy:0.946427#011validation-accuracy:0.918978\u001b[0m\n",
      "\u001b[34m[123]#011train-error:0.053445#011validation-error:0.08115#011train-accuracy:0.946555#011validation-accuracy:0.91885\u001b[0m\n",
      "\u001b[34m[124]#011train-error:0.053254#011validation-error:0.08115#011train-accuracy:0.946746#011validation-accuracy:0.91885\u001b[0m\n",
      "\u001b[34m[125]#011train-error:0.053126#011validation-error:0.081278#011train-accuracy:0.946874#011validation-accuracy:0.918722\u001b[0m\n",
      "\u001b[34m[126]#011train-error:0.05303#011validation-error:0.081278#011train-accuracy:0.94697#011validation-accuracy:0.918722\u001b[0m\n",
      "\u001b[34m[127]#011train-error:0.052838#011validation-error:0.08115#011train-accuracy:0.947162#011validation-accuracy:0.91885\u001b[0m\n",
      "\u001b[34m[128]#011train-error:0.052679#011validation-error:0.080767#011train-accuracy:0.947321#011validation-accuracy:0.919233\u001b[0m\n",
      "\u001b[34m[129]#011train-error:0.052487#011validation-error:0.080767#011train-accuracy:0.947513#011validation-accuracy:0.919233\u001b[0m\n",
      "\u001b[34m[130]#011train-error:0.052199#011validation-error:0.081789#011train-accuracy:0.947801#011validation-accuracy:0.918211\u001b[0m\n",
      "\u001b[34m[131]#011train-error:0.052199#011validation-error:0.081534#011train-accuracy:0.947801#011validation-accuracy:0.918466\u001b[0m\n",
      "\u001b[34m[132]#011train-error:0.052072#011validation-error:0.081278#011train-accuracy:0.947928#011validation-accuracy:0.918722\u001b[0m\n",
      "\u001b[34m[133]#011train-error:0.051688#011validation-error:0.081534#011train-accuracy:0.948312#011validation-accuracy:0.918466\u001b[0m\n",
      "\u001b[34m[134]#011train-error:0.051529#011validation-error:0.081406#011train-accuracy:0.948471#011validation-accuracy:0.918594\u001b[0m\n",
      "\u001b[34m[135]#011train-error:0.051273#011validation-error:0.081406#011train-accuracy:0.948727#011validation-accuracy:0.918594\u001b[0m\n",
      "\u001b[34m[136]#011train-error:0.050986#011validation-error:0.081789#011train-accuracy:0.949014#011validation-accuracy:0.918211\u001b[0m\n",
      "\u001b[34m[137]#011train-error:0.050634#011validation-error:0.081534#011train-accuracy:0.949366#011validation-accuracy:0.918466\u001b[0m\n",
      "\u001b[34m[138]#011train-error:0.050442#011validation-error:0.081789#011train-accuracy:0.949558#011validation-accuracy:0.918211\u001b[0m\n",
      "\u001b[34m[139]#011train-error:0.050219#011validation-error:0.081917#011train-accuracy:0.949781#011validation-accuracy:0.918083\u001b[0m\n",
      "\u001b[34m[140]#011train-error:0.050315#011validation-error:0.081789#011train-accuracy:0.949685#011validation-accuracy:0.918211\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[141]#011train-error:0.050091#011validation-error:0.081406#011train-accuracy:0.949909#011validation-accuracy:0.918594\u001b[0m\n",
      "\u001b[34m[142]#011train-error:0.050059#011validation-error:0.080767#011train-accuracy:0.949941#011validation-accuracy:0.919233\u001b[0m\n",
      "\u001b[34m[143]#011train-error:0.049804#011validation-error:0.080639#011train-accuracy:0.950196#011validation-accuracy:0.919361\u001b[0m\n",
      "\u001b[34m[144]#011train-error:0.049548#011validation-error:0.080639#011train-accuracy:0.950452#011validation-accuracy:0.919361\u001b[0m\n",
      "\u001b[34m[145]#011train-error:0.04926#011validation-error:0.081022#011train-accuracy:0.95074#011validation-accuracy:0.918978\u001b[0m\n",
      "\u001b[34m[146]#011train-error:0.049133#011validation-error:0.081022#011train-accuracy:0.950867#011validation-accuracy:0.918978\u001b[0m\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n",
      "2020-04-11 23:29:46 Starting - Preparing the instances for training\n",
      "2020-04-11 23:29:46 Downloading - Downloading input data\n",
      "2020-04-11 23:29:46 Training - Training image download completed. Training in progress.\n",
      "2020-04-11 23:29:46 Uploading - Uploading generated training model\n",
      "2020-04-11 23:29:46 Completed - Training job completed\u001b[34m2020-04-11 23:29:29,161 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,163 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,173 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:29,434 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpqa3w7xe9/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=4364 sha256=6d248af31d0c5877c0d4fddf02a50a6571124fea80647151bdb4a382e97a8989\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iwgj36tr/wheels/f0/1b/99/1cde50cce24fa5090ec713f15b2e80ca3ee04ef587c45ff9c9\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:30,671 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,690 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,703 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:33,713 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"processor_module\": \"dpp6\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"processor_module\":\"dpp6\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"processor_module\":\"dpp6\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-262002448484/xgb-c1-202-notebook-run-11-22-41-31-dpp6-train-11-23-27-22/source/sourcedir.tar.gz\",\"module_name\":\"trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--processor_module\",\"dpp6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSOR_MODULE=dpp6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python trainer.py --processor_module dpp6\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 23:29:35,672 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "# Get a data transformation model from chosen candidate\n",
    "best_candidate = automl_interactive_runner.choose_candidate(df_tuning_job_analytics, best_training_job)\n",
    "best_data_transformer_model = best_candidate.get_data_transformer_model(role=SAGEMAKER_ROLE, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "# Our first data transformation container will always return recordio-protobuf format\n",
    "best_data_transformer_model.env[\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\"] = 'application/x-recordio-protobuf'\n",
    "# Add environment variable for sparse encoding\n",
    "if best_candidate.data_transformer_step.sparse_encoding:\n",
    "    best_data_transformer_model.env[\"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\"] = '1'\n",
    "\n",
    "# Get a algo model from chosen training job of the candidate\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})\n",
    "\n",
    "# Final pipeline model is composed of data transformation models and algo model and an\n",
    "# inverse label transform model if we need to transform the intermediates back to non-numerical value\n",
    "model_containers = [best_data_transformer_model, best_algo_model]\n",
    "if best_candidate.transforms_label:\n",
    "    model_containers.append(best_candidate.get_data_transformer_model(\n",
    "        transform_mode=\"inverse-label-transform\",\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        sagemaker_session=SAGEMAKER_SESSION))\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"AutoML-{}\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name),\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    models=model_containers,\n",
    "    vpc_config=AUTOML_LOCAL_RUN_CONFIG.vpc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Best Pipeline\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. You can customize the initial instance count and instance type used to deploy this model.\n",
    "2. Endpoint name can be changed to avoid conflict with existing endpoints.\n",
    "\n",
    "</div>\n",
    "\n",
    "Finally, deploy the model to SageMaker to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 03:43:38,434 INFO sagemaker: Creating model with name: AutoML-xgb-c1-202-notebook-run-11-22-41-31\n",
      "2020-04-12 03:43:39,387 INFO sagemaker: Creating endpoint with name AutoML-xgb-c1-202-notebook-run-11-22-41-31\n",
      "-"
     ]
    }
   ],
   "source": [
    "pipeline_model.deploy(initial_instance_count=1,\n",
    "                      instance_type='ml.m5.2xlarge',\n",
    "                      endpoint_name=pipeline_model.name,\n",
    "                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you could visit the sagemaker\n",
    "[endpoint console page](https://us-west-1.console.aws.amazon.com/sagemaker/home?region=us-west-1#/endpoints) to find the deployed endpoint (it'll take a few minutes to be in service).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <strong>To rerun this notebook, delete or change the name of your endpoint!</strong> <br>\n",
    "If you rerun this notebook, you'll run into an error on the last step because the endpoint already exists. You can either delete the endpoint from the endpoint console page or you can change the <code>endpoint_name</code> in the previous code block.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
